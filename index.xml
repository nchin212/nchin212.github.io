<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science Portfolio on Nicholas Chin Wei Lun</title>
    <link>https://nchin212.github.io/</link>
    <description>Recent content in Data Science Portfolio on Nicholas Chin Wei Lun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Jan 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://nchin212.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Rental Bike Prediction</title>
      <link>https://nchin212.github.io/post/rental_bike_prediction/</link>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://nchin212.github.io/post/rental_bike_prediction/</guid>
      <description>In this project, we built a regression model to predict rental bike demand. We conducted feature engineering to generate features from date and time. Much exploratory data analysis was done on average user counts over time. We implemented 2 stepwise regression models, 1 with and another without log transformation. The log transformed model achieved a higher R squared of 80%.</description>
    </item>
    
    <item>
      <title>Sentiment Analysis</title>
      <link>https://nchin212.github.io/post/sentiment_analysis/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://nchin212.github.io/post/sentiment_analysis/</guid>
      <description>In this project, we analyzed Amazon video game reviews by classifying them as positive or negative. We tokenized the reviews using 2 different vectorizers, CountVectorizer and TfidfVectorizer. We then applied naive bayes, logistic regression and support vector machine (SVM) on the 2 different vectorizers. Naive Bayes with CountVectorizer had the highest f1-score of around 88%.</description>
    </item>
    
    <item>
      <title>Credit Card Fraud Detection</title>
      <link>https://nchin212.github.io/post/credit_fraud/</link>
      <pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://nchin212.github.io/post/credit_fraud/</guid>
      <description>In this project, we analyzed credit card transactions made by European cardholders by classifying them as safe or fraudulent. We tried 2 different oversampling techniques, RandomOverSampler and Synthetic Minority Oversampling Technique (SMOTE). We also implemented logistic regression, random forest and adaboost on the imbalanced data and oversampled data. Random Forest with RandomOverSampler achieved the highest f1 score of around 87%.</description>
    </item>
    
    <item>
      <title>Customer Segmentation</title>
      <link>https://nchin212.github.io/post/customer_segmentation/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://nchin212.github.io/post/customer_segmentation/</guid>
      <description>In this project, we use recency, frequency and monetary (RFM) to analyse customer purchases from the United Kingdom. We select the number of clusters based on an elbow plot and will apply k-means clustering to segment the customers into 3 different groups: small spending customers, middle spending customers and large spending customers.</description>
    </item>
    
    <item>
      <title>Word Prediction</title>
      <link>https://nchin212.github.io/post/word_prediction/</link>
      <pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://nchin212.github.io/post/word_prediction/</guid>
      <description>In this project, we created an application that predicts the next word based on the user&amp;rsquo;s input words and achieved an accuracy score of 68%. We first combined text from US blogs, news and twitter and used quanteda to tokenize the text to 1gram, 2grams and 3grams. The stupid backoff algorithm was applied to compute scores for each word and the word with the highest score would be the next predicted word.</description>
    </item>
    
  </channel>
</rss>
