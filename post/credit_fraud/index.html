<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Credit Card Fraud Detection | Nicholas Chin Wei Lun</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.75.1" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="https://nchin212.github.io/dist/css/app.4fc0b62e4b82c997bb0041217cd6b979.css" rel="stylesheet">
    

    

    
      

    

    
    
    <meta property="og:title" content="Credit Card Fraud Detection" />
<meta property="og:description" content="Classifying transactions as safe or fraudulent" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://nchin212.github.io/post/credit_fraud/" />
<meta property="article:published_time" content="2020-12-20T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-12-20T00:00:00+00:00" />
<meta itemprop="name" content="Credit Card Fraud Detection">
<meta itemprop="description" content="Classifying transactions as safe or fraudulent">
<meta itemprop="datePublished" content="2020-12-20T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-12-20T00:00:00+00:00" />
<meta itemprop="wordCount" content="2689">



<meta itemprop="keywords" content="Python,Classification,LogisticRegression,Oversampling,RandomForest,Adaboost," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Credit Card Fraud Detection"/>
<meta name="twitter:description" content="Classifying transactions as safe or fraudulent"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  
  <header class="cover bg-top" style="background-image: url('https://nchin212.github.io/images/credit_fraud/credit.jpg');">
    <div class="pb3-m pb6-l bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://nchin212.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Nicholas Chin Wei Lun
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://nchin212.github.io/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://nchin212.github.io/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://nchin212.github.io/post/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      








<a href="https://github.com/nchin212" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>








    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Credit Card Fraud Detection</h1>
          
            <h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              Classifying transactions as safe or fraudulent
            </h2>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        PROJECTS
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=https://nchin212.github.io/post/credit_fraud/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=https://nchin212.github.io/post/credit_fraud/&amp;text=Credit%20Card%20Fraud%20Detection" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://nchin212.github.io/post/credit_fraud/&amp;title=Credit%20Card%20Fraud%20Detection" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>


      <h1 class="f1 athelas mt3 mb1">Credit Card Fraud Detection</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2020-12-20T00:00:00Z">December 20, 2020</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy avenir bg-near-white f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>In this project, we analyzed credit card transactions made by European cardholders by classifying them as safe or fraudulent. We tried 2 different oversampling techniques, RandomOverSampler and Synthetic Minority Oversampling Technique (SMOTE). We also
implemented logistic regression, random forest and adaboost on the imbalanced data and oversampled data. Random Forest with RandomOverSampler achieved the highest f1 score of around 87%.</p>
<h2 id="tools-used">Tools Used</h2>
<ul>
<li>Language: Python</li>
<li>Packages: pandas, numpy, matplotlib, seaborn, sklearn, imblearn</li>
<li>Data: <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud">Kaggle</a></li>
<li>Topics: Python, Classification, Data Imbalance, Oversampling, RandomOverSampler, SMOTE, Logistic Regression, Random Forest, Adaboost</li>
</ul>
<h2 id="synopsis">Synopsis</h2>
<p>Credit card companies handle numerous credit card transactions each day and there could be some cases of fraudulent transactions, where customers are charged for items they did not purchase. As such, it is important for companies to detect these fraudulent transactions to improve customer security and build up customer confidence in the company. In this project, we will explore some methods to resolve data imbalance and use logistic regression, random forest and adaboost to classify the transactions as safe or fraudulent.</p>
<h2 id="data">Data</h2>
<p>The dataset is taken from <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud">Kaggle</a>. It contains transactions made by credit cards in September 2013 by European cardholders. Due to confidentiality issues, Kaggle is unable to provide the original features and more background information about the data. It contains the following columns:</p>
<p><img src="https://nchin212.github.io/images/credit_fraud/table1.png" alt="png"></p>
<h2 id="loading-in-the-data">Loading in the Data</h2>
<p>Load in the libraries.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> seaborn <span style="color:#f92672">as</span> sns

<span style="color:#f92672">%</span>matplotlib inline
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.preprocessing <span style="color:#f92672">import</span> StandardScaler
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split
<span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression
<span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> confusion_matrix, classification_report, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score
<span style="color:#f92672">from</span> sklearn.ensemble <span style="color:#f92672">import</span> RandomForestClassifier, AdaBoostClassifier

<span style="color:#f92672">from</span> imblearn.over_sampling <span style="color:#f92672">import</span> RandomOverSampler
<span style="color:#f92672">from</span> imblearn.over_sampling <span style="color:#f92672">import</span> SMOTE
</code></pre></div><p>Load in the csv file and check its first few rows.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">credit <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#34;creditcard.csv&#34;</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">credit<span style="color:#f92672">.</span>head()
</code></pre></div><pre><code>         V1	        V2	        V3	        V4	        V5	        V6	        V7	        V8	        V9	        V10	        ...	V22	        V23	        V24	        V25	        V26	        V27	        V28	        Class	norm_amount	norm_time
0	-1.359807	-0.072781	2.536347	1.378155	-0.338321	0.462388	0.239599	0.098698	0.363787	0.090794	...	0.277838	-0.110474	0.066928	0.128539	-0.189115	0.133558	-0.021053	0	0.244964	-1.996583
1	1.191857	0.266151	0.166480	0.448154	0.060018	-0.082361	-0.078803	0.085102	-0.255425	-0.166974	...	-0.638672	0.101288	-0.339846	0.167170	0.125895	-0.008983	0.014724	0	-0.342475	-1.996583
2	-1.358354	-1.340163	1.773209	0.379780	-0.503198	1.800499	0.791461	0.247676	-1.514654	0.207643	...	0.771679	0.909412	-0.689281	-0.327642	-0.139097	-0.055353	-0.059752	0	1.160686	-1.996562
3	-0.966272	-0.185226	1.792993	-0.863291	-0.010309	1.247203	0.237609	0.377436	-1.387024	-0.054952	...	0.005274	-0.190321	-1.175575	0.647376	-0.221929	0.062723	0.061458	0	0.140534	-1.996562
4	-1.158233	0.877737	1.548718	0.403034	-0.407193	0.095921	0.592941	-0.270533	0.817739	0.753074	...	0.798278	-0.137458	0.141267	-0.206010	0.502292	0.219422	0.215153	0	-0.073403	-1.996541
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">credit<span style="color:#f92672">.</span>shape
</code></pre></div><pre><code>(284807, 31)
</code></pre>
<h2 id="exploratory-data-analysis">Exploratory Data Analysis</h2>
<p>Plot a histogram for each column to check their distributions.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">credit<span style="color:#f92672">.</span>hist(bins<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">15</span>), color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;orange&#39;</span>);
</code></pre></div><p><img src="https://nchin212.github.io/images/credit_fraud/hist1.png" alt="png"></p>
<p>Plot the transaction amounts over time.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">credit[[<span style="color:#e6db74">&#39;Time&#39;</span>,<span style="color:#e6db74">&#39;Amount&#39;</span>]]<span style="color:#f92672">.</span>set_index(<span style="color:#e6db74">&#39;Time&#39;</span>)<span style="color:#f92672">.</span>plot(kind<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;line&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;brown&#39;</span>)
</code></pre></div><p><img src="https://nchin212.github.io/images/credit_fraud/line1.png" alt="png"></p>
<h2 id="data-cleaning">Data Cleaning</h2>
<p>Normalize the &lsquo;Amount&rsquo; column and &lsquo;Time&rsquo; column.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">credit[<span style="color:#e6db74">&#39;norm_amount&#39;</span>] <span style="color:#f92672">=</span> StandardScaler()<span style="color:#f92672">.</span>fit_transform(credit[<span style="color:#e6db74">&#39;Amount&#39;</span>]<span style="color:#f92672">.</span>values<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
credit[<span style="color:#e6db74">&#39;norm_time&#39;</span>] <span style="color:#f92672">=</span> StandardScaler()<span style="color:#f92672">.</span>fit_transform(credit[<span style="color:#e6db74">&#39;Time&#39;</span>]<span style="color:#f92672">.</span>values<span style="color:#f92672">.</span>reshape(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
credit<span style="color:#f92672">.</span>drop([<span style="color:#e6db74">&#39;Time&#39;</span>,<span style="color:#e6db74">&#39;Amount&#39;</span>],axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, inplace<span style="color:#f92672">=</span>True)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">credit<span style="color:#f92672">.</span>head()
</code></pre></div><pre><code>        V1	        V2	        V3	        V4	        V5	        V6	        V7	        V8	        V9	        V10	        ...	V22	        V23	        V24	        V25	        V26	        V27	        V28	        Class	norm_amount	norm_time
0	-1.359807	-0.072781	2.536347	1.378155	-0.338321	0.462388	0.239599	0.098698	0.363787	0.090794	...	0.277838	-0.110474	0.066928	0.128539	-0.189115	0.133558	-0.021053	0	0.244964	-1.996583
1	1.191857	0.266151	0.166480	0.448154	0.060018	-0.082361	-0.078803	0.085102	-0.255425	-0.166974	...	-0.638672	0.101288	-0.339846	0.167170	0.125895	-0.008983	0.014724	0	-0.342475	-1.996583
2	-1.358354	-1.340163	1.773209	0.379780	-0.503198	1.800499	0.791461	0.247676	-1.514654	0.207643	...	0.771679	0.909412	-0.689281	-0.327642	-0.139097	-0.055353	-0.059752	0	1.160686	-1.996562
3	-0.966272	-0.185226	1.792993	-0.863291	-0.010309	1.247203	0.237609	0.377436	-1.387024	-0.054952	...	0.005274	-0.190321	-1.175575	0.647376	-0.221929	0.062723	0.061458	0	0.140534	-1.996562
4	-1.158233	0.877737	1.548718	0.403034	-0.407193	0.095921	0.592941	-0.270533	0.817739	0.753074	...	0.798278	-0.137458	0.141267	-0.206010	0.502292	0.219422	0.215153	0	-0.073403	-1.996541
</code></pre>
<h2 id="data-imbalance">Data Imbalance</h2>
<p>We count the number of each class as follows:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">class_count <span style="color:#f92672">=</span> credit[<span style="color:#e6db74">&#39;Class&#39;</span>]<span style="color:#f92672">.</span>value_counts()
class_count
</code></pre></div><pre><code>0    284315
1       492
Name: Class, dtype: int64
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">class_count<span style="color:#f92672">.</span>plot(kind <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;bar&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;skyblue&#39;</span>)
</code></pre></div><p><img src="https://nchin212.github.io/images/credit_fraud/bar1.png" alt="png"></p>
<p>From the values and plot, there appears to be severe data imbalance. Very few transactions are fraudulent while most of the transactions are safe. This needs to be resolved as predictive models developed using conventional machine learning algorithms could be biased and inaccurate. Such models would have a bias towards classes which have a high number of instances, such as in this case, safe transactions. These models would tend to predict the transactions as safe and treat the fraudulent transactions as noise. Thus, there would be a high probability of misclassification of fraudulent transactions as safe, which is definitely not ideal.</p>
<p>One of the ways to resolve data imbalance is to resample the dataset. This can be done by undersampling or oversampling. In this case, we will use oversampling as undersampling would result in too little data.</p>
<h2 id="oversampling">Oversampling</h2>
<p>Two different oversampling techniques will be tested. They are:</p>
<ul>
<li>RandomOverSampler</li>
<li>SMOTE (Synthetic Minority Oversampling Technique)</li>
</ul>
<p>Split the data into training and test sets. Note that we only perform oversampling after data splitting and on the training data so that no information will from the test data will be used in model training.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Remove &#39;Class&#39; column</span>
output_var <span style="color:#f92672">=</span> credit[<span style="color:#e6db74">&#39;Class&#39;</span>]
credit<span style="color:#f92672">.</span>drop(<span style="color:#e6db74">&#39;Class&#39;</span>, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, inplace<span style="color:#f92672">=</span>True)
<span style="color:#75715e"># Split the data</span>
x_train, x_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(credit, output_var, test_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
</code></pre></div><h3 id="randomoversampler">RandomOverSampler</h3>
<p>RandomOverSampler involves oversampling the minority class by picking samples at random with replacement. We are going to check the number of rows before and after sampling.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Check number of rows before oversampling</span>
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Before OverSampling, counts of label &#39;1&#39;: {}&#34;</span><span style="color:#f92672">.</span>format(sum(y_train<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Before OverSampling, counts of label &#39;0&#39;: {} </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(sum(y_train<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)))
</code></pre></div><pre><code>Before OverSampling, counts of label '1': 356
Before OverSampling, counts of label '0': 199008
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Apply RandomOverSampler</span>
over_sample <span style="color:#f92672">=</span> RandomOverSampler(random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
x_train_ros, y_train_ros <span style="color:#f92672">=</span> over_sample<span style="color:#f92672">.</span>fit_resample(x_train, y_train<span style="color:#f92672">.</span>ravel())
<span style="color:#75715e"># Check number of rows after oversampling</span>
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;After OverSampling, counts of label &#39;1&#39;: {}&#34;</span><span style="color:#f92672">.</span>format(sum(y_train_ros<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;After OverSampling, counts of label &#39;0&#39;: {} </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(sum(y_train_ros<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)))
</code></pre></div><pre><code>After OverSampling, counts of label '1': 199008
After OverSampling, counts of label '0': 199008
</code></pre>
<h3 id="smote-synthetic-minority-oversampling-technique">SMOTE (Synthetic Minority Oversampling Technique)</h3>
<p>SMOTE first selects a minority class instance &lsquo;a&rsquo; at random and finds its k nearest minority class neighbors. The synthetic instance is then created by choosing one of the k nearest neighbors &lsquo;b&rsquo; at random and connecting &lsquo;a&rsquo; and &lsquo;b&rsquo; to form a line segment. The synthetic instances are generated as a convex combination of the two chosen instances &lsquo;a&rsquo; and &lsquo;b&rsquo;.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Apply SMOTE</span>
over_sample <span style="color:#f92672">=</span> SMOTE(random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)
x_train_smote, y_train_smote <span style="color:#f92672">=</span> over_sample<span style="color:#f92672">.</span>fit_resample(x_train, y_train<span style="color:#f92672">.</span>ravel())
<span style="color:#75715e"># Check number of rows after oversampling</span>
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;After OverSampling, counts of label &#39;1&#39;: {}&#34;</span><span style="color:#f92672">.</span>format(sum(y_train_smote<span style="color:#f92672">==</span><span style="color:#ae81ff">1</span>)))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;After OverSampling, counts of label &#39;0&#39;: {} </span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(sum(y_train_smote<span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>)))
</code></pre></div><pre><code>After OverSampling, counts of label '1': 199008
After OverSampling, counts of label '0': 199008
</code></pre>
<h2 id="model-building">Model Building</h2>
<p>The following models have been chosen for building:</p>
<ul>
<li>Logistic Regression</li>
<li>Random Forest (Bagging)</li>
<li>Adaboost (Boosting)</li>
</ul>
<h3 id="logistic-regression">Logistic Regression</h3>
<p>Logistic Regression is a classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 or 0, or in this case, fraudulent or safe.</p>
<p>The model will first be run on the imbalanced data, followed by  the data after oversampling (RandomOverSampler and SMOTE).</p>
<h3 id="1-logistic-regression-on-imbalanced-dataset">1) Logistic Regression on imbalanced dataset</h3>
<p>Fit the training data into logistic regression and use the model to predict on the test data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">lg <span style="color:#f92672">=</span> LogisticRegression()
lg<span style="color:#f92672">.</span>fit(x_train, y_train)

y_pred_lg <span style="color:#f92672">=</span> lg<span style="color:#f92672">.</span>predict(x_test)
</code></pre></div><p>To evaluate the model, we can plot a confusion matrix. A confusion matrix is a table that is often used to describe the performance of a classification model. It shows the number of true positives, true negatives, false positives and false negatives.</p>
<p><strong>True Positives (TP)</strong> - Actual class is 1 and predicted class is 1 (safe transactions accurately classified as safe)</p>
<p><strong>True Negatives (TN)</strong> - Actual class is 0 and predicted class is 0 (fraudulent transactions accurately classified as fraudulent)</p>
<p><strong>False Positives (FP)</strong> - Actual class is 0 but predicted class is 1 (safe transactions wrongly classified as fraudulent)</p>
<p><strong>False Negatives (FN)</strong> - Actual class is 1 but predicted class is 0 (fraudulent transactions wrongly classified as safe)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">cm <span style="color:#f92672">=</span> confusion_matrix(y_test, y_pred_lg)

<span style="color:#75715e"># Create graphics for confusion matrix</span>
labels <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Safe&#39;</span>,<span style="color:#e6db74">&#39;Fraudulent&#39;</span>]
ax<span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot()
sns<span style="color:#f92672">.</span>heatmap(cm, annot<span style="color:#f92672">=</span>True, ax <span style="color:#f92672">=</span> ax, fmt<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;d&#34;</span>);

<span style="color:#75715e"># Labels, title and ticks</span>
ax<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;Predicted labels&#39;</span>);ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;True labels&#39;</span>);
ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;Confusion Matrix&#39;</span>);
ax<span style="color:#f92672">.</span>xaxis<span style="color:#f92672">.</span>set_ticklabels(labels); ax<span style="color:#f92672">.</span>yaxis<span style="color:#f92672">.</span>set_ticklabels(labels)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://nchin212.github.io/images/credit_fraud/matrix1.png" alt="png"></p>
<p>There appears to be a large number of transactions classified correctly as safe or fraudulent. However, there are 50 false negatives, i.e. fraudulent transactions that were predicted as safe, which the model needs to improve on.</p>
<p>Since this is an imbalanced dataset, we print out the classification report, which shows the accuracy, precision, recall, f1 score and support of the model.</p>
<p><strong>Accuracy</strong> - Ratio of correctly predicted observations to the total observations, i.e. TP+TN/TP+FP+FN+TN</p>
<p><strong>Precision</strong> - Ratio of correctly predicted positive observations to the total predicted positive observations, i.e. TP/TP+FP</p>
<p><strong>Recall</strong> - Ratio of correctly predicted positive observations to all the observations in positive class, i.e. TP/TP+FN</p>
<p><strong>F1 score</strong> - Weighted average of precision and recall, usually more useful than accuracy, especially if you have an uneven class distribution, i.e 2*(Recall * Precision) / (Recall + Precision)</p>
<p><strong>Support</strong> - Number of actual occurrences of the class in the dataset</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(classification_report(y_test, y_pred_lg, digits<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>))
</code></pre></div><pre><code>              precision    recall  f1-score   support

           0    0.99941   0.99986   0.99964     85307
           1    0.87755   0.63235   0.73504       136

    accuracy                        0.99927     85443
   macro avg    0.93848   0.81611   0.86734     85443
weighted avg    0.99922   0.99927   0.99922     85443
</code></pre>
<p>The model has a precision of 0.88, recall of 0.63 and f1 score of 0.73, which shows that the model does relatively well.</p>
<p>Now, we plot a Receiver Operating Characteristic (ROC) curve. It plots the true positive rate (TPR) versus the false positive rate (FPR) as a function of the model’s threshold for classifying a positive. We then proceed to compute the Area under the curve (AUC), which is a metric to calculate the overall performance of a classification model based on area under the ROC curve.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Get false positive rate and true positive rate</span>
fpr, tpr, _ <span style="color:#f92672">=</span> roc_curve(y_test, y_pred_lg)
roc_auc <span style="color:#f92672">=</span> auc(fpr, tpr)

<span style="color:#75715e"># Plot ROC curve</span>
plt<span style="color:#f92672">.</span>figure()
plt<span style="color:#f92672">.</span>plot(fpr, tpr, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;darkorange&#39;</span>,
         lw<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ROC curve (area = </span><span style="color:#e6db74">%0.2f</span><span style="color:#e6db74">)&#39;</span> <span style="color:#f92672">%</span> roc_auc)
plt<span style="color:#f92672">.</span>plot([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>], [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>], color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;navy&#39;</span>, lw<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;--&#39;</span>)
plt<span style="color:#f92672">.</span>xlim([<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.0</span>])
plt<span style="color:#f92672">.</span>ylim([<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.05</span>])
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;False Positive Rate&#39;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;True Positive Rate&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Receiver operating characteristic curve&#39;</span>)
plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;lower right&#34;</span>)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://nchin212.github.io/images/credit_fraud/auc1.png" alt="png"></p>
<h3 id="2-logistic-regression-on-oversampled-dataset-randomoversampler">2) Logistic Regression on oversampled dataset (RandomOverSampler)</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">lg_ros <span style="color:#f92672">=</span> LogisticRegression()
lg_ros<span style="color:#f92672">.</span>fit(x_train_ros, y_train_ros)

y_pred_lg_ros <span style="color:#f92672">=</span> lg_ros<span style="color:#f92672">.</span>predict(x_test)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">cm <span style="color:#f92672">=</span> confusion_matrix(y_test, y_pred_lg_ros)

<span style="color:#75715e"># Create graphics for confusion matrix</span>
labels <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Safe&#39;</span>,<span style="color:#e6db74">&#39;Fraudulent&#39;</span>]
ax<span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot()
sns<span style="color:#f92672">.</span>heatmap(cm, annot<span style="color:#f92672">=</span>True, ax <span style="color:#f92672">=</span> ax, fmt<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;d&#34;</span>);

<span style="color:#75715e"># Labels, title and ticks</span>
ax<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;Predicted labels&#39;</span>);ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;True labels&#39;</span>);
ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;Confusion Matrix&#39;</span>);
ax<span style="color:#f92672">.</span>xaxis<span style="color:#f92672">.</span>set_ticklabels(labels); ax<span style="color:#f92672">.</span>yaxis<span style="color:#f92672">.</span>set_ticklabels(labels)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://nchin212.github.io/images/credit_fraud/matrix2.png" alt="png"></p>
<p>There appears to be 10 false negatives, which is much lower than the unbalanced dataset. However, there are significantly more false positives.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(classification_report(y_test, y_pred_lg_ros, digits<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>))
</code></pre></div><pre><code>              precision    recall  f1-score   support

           0    0.99988   0.97466   0.98711     85307
           1    0.05507   0.92647   0.10396       136

    accuracy                        0.97458     85443
   macro avg    0.52747   0.95056   0.54553     85443
weighted avg    0.99838   0.97458   0.98570     85443
</code></pre>
<p>As expected, it has a low precision of 0.05 but a high recall of 0.93.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Get false positive rate and true positive rate</span>
fpr, tpr, _ <span style="color:#f92672">=</span> roc_curve(y_test, y_pred_lg_ros)
roc_auc_ros <span style="color:#f92672">=</span> auc(fpr, tpr)

<span style="color:#75715e"># Plot ROC curve</span>
plt<span style="color:#f92672">.</span>figure()
plt<span style="color:#f92672">.</span>plot(fpr, tpr, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;darkorange&#39;</span>,
         lw<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ROC curve (area = </span><span style="color:#e6db74">%0.2f</span><span style="color:#e6db74">)&#39;</span> <span style="color:#f92672">%</span> roc_auc)
plt<span style="color:#f92672">.</span>plot([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>], [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>], color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;navy&#39;</span>, lw<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;--&#39;</span>)
plt<span style="color:#f92672">.</span>xlim([<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.0</span>])
plt<span style="color:#f92672">.</span>ylim([<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.05</span>])
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;False Positive Rate&#39;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;True Positive Rate&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Receiver operating characteristic curve&#39;</span>)
plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;lower right&#34;</span>)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://nchin212.github.io/images/credit_fraud/auc2.png" alt="png"></p>
<h3 id="3-logistic-regression-on-oversampled-dataset-smote">3) Logistic Regression on oversampled dataset (SMOTE)</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">lg_smote <span style="color:#f92672">=</span> LogisticRegression()
lg_smote<span style="color:#f92672">.</span>fit(x_train_smote, y_train_smote)

y_pred_lg_smote <span style="color:#f92672">=</span> lg_smote<span style="color:#f92672">.</span>predict(x_test)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">cm <span style="color:#f92672">=</span> confusion_matrix(y_test, y_pred_lg_smote)

<span style="color:#75715e"># Create graphics for confusion matrix</span>
labels <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;Safe&#39;</span>,<span style="color:#e6db74">&#39;Fraudulent&#39;</span>]
ax<span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplot()
sns<span style="color:#f92672">.</span>heatmap(cm, annot<span style="color:#f92672">=</span>True, ax <span style="color:#f92672">=</span> ax, fmt<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;d&#34;</span>);

<span style="color:#75715e"># Labels, title and ticks</span>
ax<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;Predicted labels&#39;</span>);ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;True labels&#39;</span>);
ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;Confusion Matrix&#39;</span>);
ax<span style="color:#f92672">.</span>xaxis<span style="color:#f92672">.</span>set_ticklabels(labels); ax<span style="color:#f92672">.</span>yaxis<span style="color:#f92672">.</span>set_ticklabels(labels)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://nchin212.github.io/images/credit_fraud/matrix3.png" alt="png"></p>
<p>It has quite similar false negatives to the oversampled data using RandomOverSampler but higher false positives.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(classification_report(y_test, y_pred_lg_smote, digits<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>))
</code></pre></div><pre><code>              precision    recall  f1-score   support

           0    0.99989   0.97331   0.98642     85307
           1    0.05283   0.93382   0.10000       136

    accuracy                        0.97325     85443
   macro avg    0.52636   0.95357   0.54321     85443
weighted avg    0.99838   0.97325   0.98501     85443
</code></pre>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Get false positive rate and true positive rate</span>
fpr, tpr, _ <span style="color:#f92672">=</span> roc_curve(y_test, y_pred_lg_smote)
roc_auc_smote <span style="color:#f92672">=</span> auc(fpr, tpr)

<span style="color:#75715e"># Plot ROC curve</span>
plt<span style="color:#f92672">.</span>figure()
plt<span style="color:#f92672">.</span>plot(fpr, tpr, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;darkorange&#39;</span>,
         lw<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ROC curve (area = </span><span style="color:#e6db74">%0.2f</span><span style="color:#e6db74">)&#39;</span> <span style="color:#f92672">%</span> roc_auc)
plt<span style="color:#f92672">.</span>plot([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>], [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>], color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;navy&#39;</span>, lw<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;--&#39;</span>)
plt<span style="color:#f92672">.</span>xlim([<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.0</span>])
plt<span style="color:#f92672">.</span>ylim([<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.05</span>])
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;False Positive Rate&#39;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;True Positive Rate&#39;</span>)
plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Receiver operating characteristic curve&#39;</span>)
plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;lower right&#34;</span>)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img src="https://nchin212.github.io/images/credit_fraud/auc3.png" alt="png"></p>
<p>The 3 methods have similar AUC scores.</p>
<h3 id="random-forest">Random Forest</h3>
<p>Random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction. It is usually trained with the “bagging” method, where a combination of learning models is used to increase the overall result.</p>
<h3 id="1-random-forest-on-imbalanced-dataset">1) Random Forest on imbalanced dataset</h3>
<p>Fit the training data into random forest and use the model to predict on the test data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">rf <span style="color:#f92672">=</span> RandomForestClassifier(n_estimators <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">42</span>)
rf<span style="color:#f92672">.</span>fit(x_train,y_train)
y_pred_rf <span style="color:#f92672">=</span>rf<span style="color:#f92672">.</span>predict(x_test)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(classification_report(y_test, y_pred_rf, digits<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>))
</code></pre></div><pre><code>              precision    recall  f1-score   support

           0    0.99968   0.99989   0.99979     85307
           1    0.92373   0.80147   0.85827       136

    accuracy                        0.99958     85443
   macro avg    0.96171   0.90068   0.92903     85443
weighted avg    0.99956   0.99958   0.99956     85443
</code></pre>
<h3 id="2-random-forest-on-oversampled-dataset-randomoversampler">2) Random Forest on oversampled dataset (RandomOverSampler)</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">rf_ros <span style="color:#f92672">=</span> RandomForestClassifier(n_estimators <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">42</span>)
rf_ros<span style="color:#f92672">.</span>fit(x_train_ros,y_train_ros)
y_pred_rf_ros <span style="color:#f92672">=</span>rf_ros<span style="color:#f92672">.</span>predict(x_test)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(classification_report(y_test, y_pred_rf_ros, digits<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>))
</code></pre></div><pre><code>              precision    recall  f1-score   support

           0    0.99971   0.99993   0.99982     85307
           1    0.94872   0.81618   0.87747       136

    accuracy                        0.99964     85443
   macro avg    0.97421   0.90805   0.93864     85443
weighted avg    0.99963   0.99964   0.99962     85443
</code></pre>
<h3 id="3-random-forest-on-oversampled-dataset-smote">3) Random Forest on oversampled dataset (SMOTE)</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">rf_smote <span style="color:#f92672">=</span> RandomForestClassifier(n_estimators <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">42</span>)
rf_smote<span style="color:#f92672">.</span>fit(x_train_smote,y_train_smote)
y_pred_rf_smote <span style="color:#f92672">=</span>rf_smote<span style="color:#f92672">.</span>predict(x_test)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(classification_report(y_test, y_pred_rf_smote, digits<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>))
</code></pre></div><pre><code>              precision    recall  f1-score   support

           0    0.99979   0.99973   0.99976     85307
           1    0.83688   0.86765   0.85199       136

    accuracy                        0.99952     85443
   macro avg    0.91833   0.93369   0.92587     85443
weighted avg    0.99953   0.99952   0.99952     85443
</code></pre>
<h3 id="adaboost">Adaboost</h3>
<p>Adaboost (Adaptive Boosting) is a boosting algorithm which converts weak learner to strong learners. A detailed explanation of how this algorithm works can be found <a href="https://www.analyticsvidhya.com/blog/2015/11/quick-introduction-boosting-algorithms-machine-learning">here</a>.</p>
<h3 id="1-adaboost-on-imbalanced-dataset">1) Adaboost on imbalanced dataset</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">ada <span style="color:#f92672">=</span> AdaBoostClassifier(n_estimators <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">42</span>)
ada<span style="color:#f92672">.</span>fit(x_train,y_train)
y_pred_ada <span style="color:#f92672">=</span> ada<span style="color:#f92672">.</span>predict(x_test)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(classification_report(y_test, y_pred_ada, digits<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>))
</code></pre></div><pre><code>              precision    recall  f1-score   support

           0    0.99967   0.99981   0.99974     85307
           1    0.87097   0.79412   0.83077       136

    accuracy                        0.99949     85443
   macro avg    0.93532   0.89697   0.91526     85443
weighted avg    0.99947   0.99949   0.99947     85443
</code></pre>
<h3 id="2-adaboost-on-oversampled-dataset-randomoversampler">2) Adaboost on oversampled dataset (RandomOverSampler)</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">ada_ros <span style="color:#f92672">=</span> AdaBoostClassifier(n_estimators <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">42</span>)
ada_ros<span style="color:#f92672">.</span>fit(x_train_ros,y_train_ros)
y_pred_ada_ros <span style="color:#f92672">=</span>ada_ros<span style="color:#f92672">.</span>predict(x_test)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(classification_report(y_test, y_pred_ada_ros, digits<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>))
</code></pre></div><pre><code>              precision    recall  f1-score   support

           0    0.99988   0.98985   0.99484     85307
           1    0.12702   0.92647   0.22340       136

    accuracy                        0.98975     85443
   macro avg    0.56345   0.95816   0.60912     85443
weighted avg    0.99849   0.98975   0.99361     85443
</code></pre>
<h3 id="3-adaboost-on-oversampled-dataset-smote">3) Adaboost on oversampled dataset (SMOTE)</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">ada_smote <span style="color:#f92672">=</span> AdaBoostClassifier(n_estimators <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">42</span>)
ada_smote<span style="color:#f92672">.</span>fit(x_train_smote,y_train_smote)
y_pred_ada_smote <span style="color:#f92672">=</span> ada_smote<span style="color:#f92672">.</span>predict(x_test)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(classification_report(y_test, y_pred_ada_smote, digits<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>))
</code></pre></div><pre><code>              precision    recall  f1-score   support

           0    0.99990   0.98349   0.99163     85307
           1    0.08333   0.94118   0.15311       136

    accuracy                        0.98343     85443
   macro avg    0.54162   0.96234   0.57237     85443
weighted avg    0.99845   0.98343   0.99030     85443
</code></pre>
<h2 id="results">Results</h2>
<p>Create a function to plot the results in a table.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">classification_table</span>(y_test, <span style="color:#f92672">*</span>args):
    df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(columns<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;Accuracy&#39;</span>,<span style="color:#e6db74">&#39;Precision&#39;</span>,<span style="color:#e6db74">&#39;Recall&#39;</span>,<span style="color:#e6db74">&#39;F1-score&#39;</span>])
    <span style="color:#66d9ef">for</span> y_pred <span style="color:#f92672">in</span> args:
        accuracy <span style="color:#f92672">=</span> accuracy_score(y_test, y_pred)
        precision <span style="color:#f92672">=</span> precision_score(y_test, y_pred)
        recall <span style="color:#f92672">=</span> recall_score(y_test, y_pred)
        f1 <span style="color:#f92672">=</span> f1_score(y_test, y_pred)

        <span style="color:#75715e"># AUC score</span>
        fpr, tpr, _ <span style="color:#f92672">=</span> roc_curve(y_test, y_pred)
        roc_auc <span style="color:#f92672">=</span> auc(fpr, tpr)

        df <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>append({<span style="color:#e6db74">&#39;Accuracy&#39;</span>: accuracy, <span style="color:#e6db74">&#39;Precision&#39;</span>: precision, <span style="color:#e6db74">&#39;Recall&#39;</span>: recall, <span style="color:#e6db74">&#39;F1-score&#39;</span>: f1, <span style="color:#e6db74">&#39;AUC&#39;</span>: roc_auc}, ignore_index<span style="color:#f92672">=</span>True)
    <span style="color:#66d9ef">return</span> df
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">combined <span style="color:#f92672">=</span> classification_table(y_test,
                                y_pred_lg, y_pred_lg_ros, y_pred_lg_smote,
                                y_pred_rf, y_pred_rf_ros, y_pred_rf_smote,
                                y_pred_ada, y_pred_ada_ros, y_pred_ada_smote)
combined<span style="color:#f92672">.</span>index <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;LogReg Imbalanced&#39;</span>, <span style="color:#e6db74">&#39;LogReg RandomOverSampler&#39;</span>,<span style="color:#e6db74">&#39;LogReg SMOTE&#39;</span>,
                  <span style="color:#e6db74">&#39;RF Imbalanced&#39;</span>, <span style="color:#e6db74">&#39;RF RandomOverSampler&#39;</span>,<span style="color:#e6db74">&#39;RF SMOTE&#39;</span>,
                  <span style="color:#e6db74">&#39;Ada Imbalanced&#39;</span>, <span style="color:#e6db74">&#39;Ada RandomOverSampler&#39;</span>,<span style="color:#e6db74">&#39;Ada SMOTE&#39;</span>]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">combined
</code></pre></div><p><img src="https://nchin212.github.io/images/credit_fraud/table2.png" alt="png"></p>
<p>Since this is an unbalanced dataset, accuracy is not the correct metric to use to compare the models as the models will tend to predict the majority class, resulting in high accuracy rates even though the minority class has been classified wrongly. Instead, we should compare the models using their f1-scores.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fig, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">8</span>))
x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">3</span>)
bar_width <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>
b1 <span style="color:#f92672">=</span> ax<span style="color:#f92672">.</span>bar(x, combined<span style="color:#f92672">.</span>loc[combined<span style="color:#f92672">.</span>index<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>contains(<span style="color:#e6db74">&#39;Imbalanced&#39;</span>), <span style="color:#e6db74">&#39;F1-score&#39;</span>],
            width<span style="color:#f92672">=</span>bar_width, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;Imbalanced&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;deepskyblue&#39;</span>, edgecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;black&#39;</span>)
b2 <span style="color:#f92672">=</span> ax<span style="color:#f92672">.</span>bar(x <span style="color:#f92672">+</span> bar_width, combined<span style="color:#f92672">.</span>loc[combined<span style="color:#f92672">.</span>index<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>contains(<span style="color:#e6db74">&#39;RandomOverSampler&#39;</span>), <span style="color:#e6db74">&#39;F1-score&#39;</span>],
            width<span style="color:#f92672">=</span>bar_width, label<span style="color:#f92672">=</span> <span style="color:#e6db74">&#39; RandomOverSampler&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;limegreen&#39;</span>, edgecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;black&#39;</span>)
b3 <span style="color:#f92672">=</span> ax<span style="color:#f92672">.</span>bar(x <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>bar_width, combined<span style="color:#f92672">.</span>loc[combined<span style="color:#f92672">.</span>index<span style="color:#f92672">.</span>str<span style="color:#f92672">.</span>contains(<span style="color:#e6db74">&#39;SMOTE&#39;</span>), <span style="color:#e6db74">&#39;F1-score&#39;</span>],
            width<span style="color:#f92672">=</span>bar_width, label<span style="color:#f92672">=</span> <span style="color:#e6db74">&#39; SMOTE&#39;</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;darkorange&#39;</span>, edgecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;black&#39;</span>)

<span style="color:#75715e"># Add legend</span>
ax<span style="color:#f92672">.</span>legend()

<span style="color:#75715e"># Fix x-axis labels</span>
ax<span style="color:#f92672">.</span>set_xticks(x <span style="color:#f92672">+</span> bar_width)
ax<span style="color:#f92672">.</span>set_xticklabels([<span style="color:#e6db74">&#39;Logistic Regression&#39;</span>,<span style="color:#e6db74">&#39;Random Forest&#39;</span>, <span style="color:#e6db74">&#39;AdaBoost&#39;</span>])

<span style="color:#75715e"># Add axis and chart labels.</span>
ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;F1-score&#39;</span>)
ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;F1-score by Model and Oversampling Technique&#39;</span>, pad<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>)
</code></pre></div><p><img src="https://nchin212.github.io/images/credit_fraud/bar2.png" alt="png"></p>
<p>Both logistic regression and adaBoost appear to perform very well on the imbalanced dataset but not on the oversampled datasets. Random forest performs very well overall and the best model performance is random forest with RandomOverSampler with a f1-score of 87.7%. However, one may consider comparing the models using recall as companies would want the model to be sensitive to fraudulent transactions and have a low number of false negatives. In that case, adaboost with SMOTE would be the best model with a recall of 94.1%.</p>
<p><a href="https://github.com/nchin212/Credit_Card_Fraud_Detection">Link to Github repository</a></p>
<ul class="pa0">
  
   <li class="list">
     <a href="https://nchin212.github.io/tags/Python" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Python</a>
   </li>
  
   <li class="list">
     <a href="https://nchin212.github.io/tags/Classification" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Classification</a>
   </li>
  
   <li class="list">
     <a href="https://nchin212.github.io/tags/LogisticRegression" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">LogisticRegression</a>
   </li>
  
   <li class="list">
     <a href="https://nchin212.github.io/tags/Oversampling" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Oversampling</a>
   </li>
  
   <li class="list">
     <a href="https://nchin212.github.io/tags/RandomForest" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">RandomForest</a>
   </li>
  
   <li class="list">
     <a href="https://nchin212.github.io/tags/Adaboost" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Adaboost</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "https-nchin212-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l"><div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">What&#39;s in this post</p>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#tools-used">Tools Used</a></li>
    <li><a href="#synopsis">Synopsis</a></li>
    <li><a href="#data">Data</a></li>
    <li><a href="#loading-in-the-data">Loading in the Data</a></li>
    <li><a href="#exploratory-data-analysis">Exploratory Data Analysis</a></li>
    <li><a href="#data-cleaning">Data Cleaning</a></li>
    <li><a href="#data-imbalance">Data Imbalance</a></li>
    <li><a href="#oversampling">Oversampling</a>
      <ul>
        <li><a href="#randomoversampler">RandomOverSampler</a></li>
        <li><a href="#smote-synthetic-minority-oversampling-technique">SMOTE (Synthetic Minority Oversampling Technique)</a></li>
      </ul>
    </li>
    <li><a href="#model-building">Model Building</a>
      <ul>
        <li><a href="#logistic-regression">Logistic Regression</a></li>
        <li><a href="#1-logistic-regression-on-imbalanced-dataset">1) Logistic Regression on imbalanced dataset</a></li>
        <li><a href="#2-logistic-regression-on-oversampled-dataset-randomoversampler">2) Logistic Regression on oversampled dataset (RandomOverSampler)</a></li>
        <li><a href="#3-logistic-regression-on-oversampled-dataset-smote">3) Logistic Regression on oversampled dataset (SMOTE)</a></li>
        <li><a href="#random-forest">Random Forest</a></li>
        <li><a href="#1-random-forest-on-imbalanced-dataset">1) Random Forest on imbalanced dataset</a></li>
        <li><a href="#2-random-forest-on-oversampled-dataset-randomoversampler">2) Random Forest on oversampled dataset (RandomOverSampler)</a></li>
        <li><a href="#3-random-forest-on-oversampled-dataset-smote">3) Random Forest on oversampled dataset (SMOTE)</a></li>
        <li><a href="#adaboost">Adaboost</a></li>
        <li><a href="#1-adaboost-on-imbalanced-dataset">1) Adaboost on imbalanced dataset</a></li>
        <li><a href="#2-adaboost-on-oversampled-dataset-randomoversampler">2) Adaboost on oversampled dataset (RandomOverSampler)</a></li>
        <li><a href="#3-adaboost-on-oversampled-dataset-smote">3) Adaboost on oversampled dataset (SMOTE)</a></li>
      </ul>
    </li>
    <li><a href="#results">Results</a></li>
  </ul>
</nav>
  </div>




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="https://nchin212.github.io/post/customer_segmentation/">Customer Segmentation</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://nchin212.github.io" >
    &copy;  Nicholas Chin Wei Lun 2021 
  </a>
    <div>








<a href="https://github.com/nchin212" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>







</div>
  </div>
</footer>

    

  <script src="https://nchin212.github.io/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
